{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import pandas as pd\n",
    "import re\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('../audioset_tagging_cnn/')\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from pytorch.models import *\n",
    "from utils.notebooks_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '../../FG_2020/'\n",
    "\n",
    "reduced_sample_rate = 'data/Reduced_sample_rate'\n",
    "reduced_sample_rate_path = os.path.join(data_root, reduced_sample_rate)\n",
    "\n",
    "separated_audio = 'data/Separated_audio'\n",
    "separated_audio_path = os.path.join(data_root, separated_audio)\n",
    "\n",
    "# downgraded and dropped14_interpolated10 labels paths\n",
    "# labels = 'labels/dropped14_interpolated10'\n",
    "labels = 'labels/downgraded'\n",
    "labels_path = os.path.join(data_root, labels)\n",
    "\n",
    "features = 'features'\n",
    "\n",
    "log_root = '../logs/'\n",
    "tb_log_root = '../logs/tb/'\n",
    "\n",
    "features_type = 'wave'\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "class_names = ['Neutral', 'Anger', 'Disgust', 'Fear', 'Happiness', 'Sadness', 'Surprise']\n",
    "\n",
    "# Is train mode?\n",
    "is_train_mode = True\n",
    "\n",
    "# Due to memory limit\n",
    "is_test = lambda ds: (ds == 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply window to wave\n",
    "def apply_window(features, labels, window_width, sr):\n",
    "    features = np.transpose(features)\n",
    "    ratio = int(len(features) / len(labels))\n",
    "    x_center = int((window_width - 1) / 2)\n",
    "    res_x = []\n",
    "    res_y = []\n",
    "    \n",
    "    if len(features) < window_width * sr:\n",
    "        features = np.pad(features, [(0, window_width * sr - len(features))], mode='constant')\n",
    "    \n",
    "    for idx, lab in enumerate(labels):\n",
    "        x_arr = None\n",
    "        if idx < x_center:\n",
    "            x_arr = np.concatenate((np.flip(features[(idx + 1) * ratio: (idx + x_center + 1) * ratio]), \n",
    "                                    features[idx * ratio: (idx + 1) * ratio],\n",
    "                                    features[(idx + 1) * ratio: (idx + x_center + 1) * ratio]), axis=0)\n",
    "            x_arr = x_arr[0:window_width * x_center * ratio]\n",
    "        elif len(features) < (idx + x_center + 1) * ratio:\n",
    "            x_arr = np.concatenate((features[(idx - x_center) * ratio: idx * ratio], \n",
    "                                    features[idx * ratio: (idx + 1) * ratio],\n",
    "                                    np.flip(features[(idx - x_center) * ratio: idx * ratio])), axis=0)           \n",
    "            \n",
    "            x_arr = x_arr[0:window_width * x_center * ratio]\n",
    "        else:\n",
    "            x_arr = features[(idx - x_center) * ratio: (idx + x_center + 1) * ratio]\n",
    "\n",
    "        res_x.append(np.transpose(x_arr))\n",
    "        res_y.append(lab)\n",
    "        \n",
    "    return np.asarray(res_x), np.asarray(res_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract features on train set: 100%|██████████| 253/253 [00:14<00:00, 17.99it/s]\n",
      "Extract features on valid set: 100%|██████████| 70/70 [00:17<00:00,  4.04it/s]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "sr = 16000\n",
    "\n",
    "window_width = 3 * 5 # labels (input size): 3 seconds * 5 labels = 15 labels\n",
    "\n",
    "# dict for train mode\n",
    "all_data = {\n",
    "    'train': {\n",
    "        'x': [],\n",
    "        'y': [],\n",
    "    },\n",
    "    'valid': {\n",
    "        'x': [],\n",
    "        'y': [],\n",
    "    }\n",
    "}\n",
    "\n",
    "# dict for mapping filenames to features and predictions\n",
    "files_data = {\n",
    "    'train': {\n",
    "    },\n",
    "    'valid': {\n",
    "    },\n",
    "    'test': {  \n",
    "    }\n",
    "}\n",
    "\n",
    "for ds in ['train', 'valid', 'test']:\n",
    "    if is_test(ds):\n",
    "        continue\n",
    "    all_samples = []\n",
    "    \n",
    "    for i in tqdm(os.listdir(os.path.join(labels_path, ds)), desc='Extract features on {} set'.format(ds)):\n",
    "        fp = os.path.join(separated_audio_path, i).replace('.txt', '_vocals.wav').replace('_left', '').replace('_right', '')\n",
    "        if not os.path.exists(fp):\n",
    "            continue\n",
    "\n",
    "        # Extract wave\n",
    "        wave, sr = librosa.load(fp, sr)\n",
    "        \n",
    "        if ds == 'test':\n",
    "            meta = np.full(int(len(wave) / 3242), -1)\n",
    "            x, y = apply_window(wave, meta, window_width, sr)\n",
    "        else:\n",
    "            meta = pd.read_csv(os.path.join(labels_path, ds, i)).values.squeeze()\n",
    "        \n",
    "            samples_ratio = int(len(wave) / len(meta))\n",
    "            diff = len(meta) * samples_ratio - len(wave)\n",
    "            \n",
    "            x, y = apply_window(wave, meta, window_width, sr)\n",
    "            \n",
    "        if is_train_mode:\n",
    "            x = x[y != -1]\n",
    "            y = y[y != -1]\n",
    "        \n",
    "            all_data[ds]['x'].extend(x)\n",
    "            all_data[ds]['y'].extend(y)\n",
    "        else:\n",
    "            if len(y) > 0:\n",
    "                file_dict = {\n",
    "                    'x': x,\n",
    "                    'y': y\n",
    "                }\n",
    "    \n",
    "                files_data[ds][os.path.join(separated_audio_path, i)] = file_dict\n",
    "\n",
    "if is_train_mode:\n",
    "    max_len = max([len(i) for ds in ['train', 'valid'] for i in all_data[ds]['x']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomTensorDataset(Dataset):\n",
    "    \"\"\"TensorDataset with support of transforms.\n",
    "    \"\"\"\n",
    "    def __init__(self, x_np, y_tensor, max_len, transform=None):\n",
    "        self.x_np = x_np\n",
    "        self.y = y_tensor\n",
    "        self.max_len = max_len\n",
    "        self.transform = transform\n",
    "        \n",
    "    def expand_array(self, x):\n",
    "        return np.pad(x, [(0, self.max_len - len(x))], mode='constant')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.max_len == 0:\n",
    "            x = torch.Tensor(self.x_np[index])\n",
    "        else:\n",
    "            x = torch.Tensor(self.expand_array(self.x_np[index]))\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        y = self.y[index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run it in train mode only\n",
    "if is_train_mode:\n",
    "    define_seed(12)\n",
    "\n",
    "    y_train = torch.LongTensor(all_data['train']['y'])\n",
    "    y_valid = torch.LongTensor(all_data['valid']['y'])\n",
    "\n",
    "    class_sample_count = np.unique(y_train, return_counts=True)[1]\n",
    "    class_weights = torch.Tensor(max(class_sample_count) / class_sample_count)\n",
    "\n",
    "    train_dataset = CustomTensorDataset(all_data['train']['x'], y_train, max_len, transform=None)\n",
    "    valid_dataset = CustomTensorDataset(all_data['valid']['x'], y_valid, max_len, transform=None)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                                   num_workers=6, shuffle=True)\n",
    "\n",
    "    valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, \n",
    "                                                   shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transfer_Cnn14(nn.Module):\n",
    "    def __init__(self, pretrained_path, classes_num, pretrain, freeze_base):\n",
    "        \"\"\"Classifier for a new task using pretrained Cnn14 as a sub module.\n",
    "        \"\"\"\n",
    "        super(Transfer_Cnn14, self).__init__()\n",
    "\n",
    "        self.load_base(pretrain, pretrained_path)\n",
    "        \n",
    "        # Transfer to another task layer\n",
    "        self.classifier = nn.Linear(2048, classes_num, bias=True)\n",
    "\n",
    "        if freeze_base:\n",
    "            for param in self.base.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "    def load_base(self, pretrain, pretrained_path):\n",
    "        self.base = Cnn14(sample_rate=16000, window_size=1024, hop_size=320, mel_bins=64, \n",
    "                          fmin=50, fmax=14000, classes_num=527)\n",
    "        \n",
    "        if pretrain:\n",
    "            logging.info('Load pretrained model from {}'.format(pretrained_path))\n",
    "            checkpoint = torch.load(pretrained_path)\n",
    "            self.base.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.classifier)\n",
    "\n",
    "    def forward(self, x, mixup_lambda=None):\n",
    "        \"\"\"Input: (batch_size, 1, time_steps, mel_bins)\n",
    "        \"\"\"\n",
    "        output_dict = self.base(x, mixup_lambda)\n",
    "        embedding = output_dict['embedding']\n",
    "\n",
    "        clipwise_output =  self.classifier(embedding)\n",
    "        output_dict['clipwise_output'] = clipwise_output\n",
    " \n",
    "        return output_dict['clipwise_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, f1_score, accuracy_score\n",
    "\n",
    "def custom_score(targets, predicts, average='macro'):\n",
    "    return 0.67 * f1_score(targets, predicts, average='macro') + 0.33 * accuracy_score(targets, predicts) \n",
    "\n",
    "# run it in train mode only\n",
    "if is_train_mode:\n",
    "    # %%capture output\n",
    "\n",
    "    define_seed(12)\n",
    "    pretrained_path = '../models/pretrained/Cnn14_mAP=0.431.pth'\n",
    "    model = Transfer_Cnn14(pretrained_path=pretrained_path, classes_num=len(class_names), \n",
    "                           pretrain=True, freeze_base=False)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    loss = torch.nn.CrossEntropyLoss(weight=class_weights.cuda())\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999), \n",
    "                                 eps=1e-08, weight_decay=0., amsgrad=True)\n",
    "\n",
    "    model, max_epoch, max_performance = train_model(model, loss, optimizer, None, num_epochs=50, \n",
    "                                                    device=device, train_dataloader=train_dataloader, \n",
    "                                                    valid_dataloader=valid_dataloader,\n",
    "                                                    class_names=class_names,\n",
    "                                                    log_root=log_root,\n",
    "                                                    tb_log_root=tb_log_root,\n",
    "                                                    features_name=features_type,\n",
    "                                                    experiment_name='fg2020-LossWeighted-PANN-CNN14-50',\n",
    "                                                    metrics=[custom_score, f1_score, accuracy_score],\n",
    "                                                    log_iter=[])\n",
    "    \n",
    "    print('Epoch: {0}\\n'.format(max_epoch))\n",
    "    print(max_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(x, y, max_len, model, model_name, model_epoch, log_root, batch_size):\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    dataset = CustomTensorDataset(x, y, max_len, transform=None)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=6)\n",
    "\n",
    "    dictionary_path = get_model_by_epoch(os.path.join(log_root, '{0}'.format(model_name)), model_epoch)\n",
    "    checkpoint = torch.load(dictionary_path)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        predicts = None\n",
    "        with torch.set_grad_enabled(False):\n",
    "            preds = model(inputs)\n",
    "        \n",
    "        predicts = torch.nn.functional.softmax(preds, dim=1).data.cpu().numpy()\n",
    "        all_labels.append(labels.data.cpu().numpy())\n",
    "        all_predictions.append(predicts)\n",
    "        \n",
    "    return np.concatenate(all_predictions), np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performance of existing model\n",
    "pretrained_path = '../models/pretrained/Cnn14_mAP=0.431.pth'\n",
    "model = Transfer_Cnn14(pretrained_path=pretrained_path, \n",
    "                       classes_num=len(class_names), \n",
    "                       pretrain=True, \n",
    "                       freeze_base=False)\n",
    "\n",
    "model_name = 'wave_fg2020-LossWeighted-PANN-CNN14-50'\n",
    "\n",
    "y_train = torch.LongTensor(all_data['train']['y'])\n",
    "y_valid = torch.LongTensor(all_data['valid']['y'])\n",
    "\n",
    "probas, labels = predict_proba(all_data['train']['x'], y_train, max_len, model, model_name, 45, log_root, batch_size)\n",
    "preds = probas.argmax(axis=1)\n",
    "print('Metrics: F1: {0}, Acc: {1}, Custom: {2}'.format(f1_score(labels, preds, average='macro'),\n",
    "                                                       accuracy_score(labels, preds),\n",
    "                                                       custom_score(labels, preds, 'macro')))\n",
    "\n",
    "probas, labels = predict_proba(all_data['valid']['x'], y_valid, max_len, model, model_name, 45, log_root, batch_size)\n",
    "preds = probas.argmax(axis=1)\n",
    "print('Metrics: F1: {0}, Acc: {1}, Custom: {2}'.format(f1_score(labels, preds, average='macro'),\n",
    "                                                       accuracy_score(labels, preds),\n",
    "                                                       custom_score(labels, preds, 'macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253/253 [09:11<00:00,  2.18s/it]\n",
      "100%|██████████| 70/70 [02:44<00:00,  2.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get train, valid, and test predictions\n",
    "pretrained_path = '../models/pretrained/Cnn14_mAP=0.431.pth'\n",
    "model = Transfer_Cnn14(pretrained_path=pretrained_path, \n",
    "                       classes_num=len(class_names), \n",
    "                       pretrain=True, \n",
    "                       freeze_base=False)\n",
    "\n",
    "model_name = 'wave_fg2020-LossWeighted-PANN-CNN14-50'\n",
    "\n",
    "for ds in ['train', 'valid', 'test']:\n",
    "    if is_test(ds):\n",
    "        continue\n",
    "    for f in tqdm(files_data[ds]):\n",
    "        x_train = torch.Tensor(files_data[ds][f]['x'])\n",
    "        y_train = torch.LongTensor(files_data[ds][f]['y'])\n",
    "        \n",
    "        probas, labels = predict_proba(x_train, y_train, 0, model, model_name, 45, log_root, batch_size)\n",
    "        \n",
    "        res = np.concatenate((probas, np.expand_dims(labels, axis=1)), axis=1)\n",
    "        \n",
    "        os.makedirs(os.path.join(model_name, ds), exist_ok=True)\n",
    "        \n",
    "        fn = os.path.splitext(os.path.basename(f))[0]\n",
    "        np.savetxt(os.path.join(model_name, ds, \"{0}.csv\".format(fn)), res, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlenv)",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}