{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import pandas as pd\n",
    "import re\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('../audioset_tagging_cnn/')\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from pytorch.models import *\n",
    "from utils.notebooks_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/media/maxim/SStorage/FG_2020/'\n",
    "\n",
    "reduced_sample_rate = 'data/Reduced_sample_rate'\n",
    "reduced_sample_rate_path = os.path.join(data_root, reduced_sample_rate)\n",
    "\n",
    "separated_audio = 'data/Separated_audio'\n",
    "separated_audio_path = os.path.join(data_root, separated_audio)\n",
    "\n",
    "labels = 'labels/downgraded'\n",
    "labels_path = os.path.join(data_root, labels)\n",
    "\n",
    "features = 'features'\n",
    "\n",
    "log_root = '/media/maxim/SStorage/FG_2020/logs/'\n",
    "tb_log_root = '/media/maxim/SStorage/FG_2020/logs/tb/'\n",
    "\n",
    "features_type = 'mel_64x32'\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "class_names = ['Neutral', 'Anger', 'Disgust', 'Fear', 'Happiness', 'Sadness', 'Surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract features on train set:   0%|          | 0/253 [00:00<?, ?it/s]/home/maxim/anaconda3/envs/mlenv/lib/python3.7/site-packages/librosa/filters.py:222: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n",
      "Extract features on train set: 100%|██████████| 253/253 [00:16<00:00, 15.02it/s]\n",
      "Extract features on valid set: 100%|██████████| 70/70 [00:06<00:00, 10.99it/s]\n",
      "Extract features on test set: 100%|██████████| 223/223 [00:12<00:00, 17.18it/s]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "samples_ratio = 32\n",
    "sr = 16000\n",
    "\n",
    "n_fft = int(sr * (0.2 / samples_ratio)) # window_width ms\n",
    "hop_length = int(sr * (0.2 / samples_ratio)) # step ms\n",
    "\n",
    "all_data = {\n",
    "    'train': {\n",
    "        'x': [],\n",
    "        'y': [],\n",
    "    },\n",
    "    'valid': {\n",
    "        'x': [],\n",
    "        'y': [],\n",
    "    }\n",
    "}\n",
    "\n",
    "files_data = {\n",
    "    'train': {\n",
    "    },\n",
    "    'valid': {\n",
    "    },\n",
    "    'test': {  \n",
    "    }\n",
    "}\n",
    "\n",
    "for ds in ['train', 'valid', 'test']:\n",
    "    all_samples = []\n",
    "    \n",
    "    for i in tqdm(os.listdir(os.path.join(labels_path, ds)), desc='Extract features on {} set'.format(ds)):\n",
    "        fp = os.path.join(separated_audio_path, i).replace('.txt', '_vocals.wav').replace('_left', '').replace('_right', '')\n",
    "        if not os.path.exists(fp):\n",
    "            continue\n",
    "            \n",
    "        # Extract features\n",
    "        wave, sr = librosa.load(fp, sr)\n",
    "        s = librosa.feature.melspectrogram(y=wave, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=64)\n",
    "        log_mels = librosa.power_to_db(s, ref=np.max)\n",
    "        \n",
    "        if ds == 'test':\n",
    "            meta_size = int(log_mels.shape[1] / samples_ratio)\n",
    "            diff = meta_size * samples_ratio - log_mels.shape[1]\n",
    "            if diff < 0:\n",
    "                log_mels = log_mels[:, 0:diff]\n",
    "            \n",
    "            extracted_feats = np.asarray(np.split(log_mels, meta_size, axis=1))\n",
    "            meta = np.full((len(extracted_feats),), -1)\n",
    "        else:\n",
    "            meta = pd.read_csv(os.path.join(labels_path, ds, i)).values.squeeze()\n",
    "    \n",
    "            diff = meta.shape[0] * samples_ratio - log_mels.shape[1]\n",
    "        \n",
    "            if diff < 0:\n",
    "                log_mels = log_mels[:, 0:diff]\n",
    "            else:\n",
    "                diff = meta.shape[0] - int(log_mels.shape[1] / samples_ratio)\n",
    "                meta = meta[0:-diff]\n",
    "                log_mels = log_mels[:, 0: meta.shape[0] * samples_ratio]\n",
    "        \n",
    "            extracted_feats = np.asarray(np.split(log_mels, meta.shape[0], axis=1))\n",
    "        \n",
    "#             extracted_feats = extracted_feats[meta != -1]\n",
    "#             meta = meta[meta != -1]\n",
    "        \n",
    "#         all_data[ds]['x'].extend(extracted_feats)    \n",
    "#         all_data[ds]['y'].extend(meta)\n",
    "                \n",
    "        if len(meta) > 0:\n",
    "            file_dict = {\n",
    "                'x': extracted_feats,\n",
    "                'y': meta\n",
    "            }\n",
    "    \n",
    "            files_data[ds][os.path.join(separated_audio_path, i)] = file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomTensorDataset(Dataset):\n",
    "    \"\"\"TensorDataset with support of transforms.\n",
    "    \"\"\"\n",
    "    def __init__(self, tensors, transform=None):\n",
    "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "        self.tensors = tensors\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.tensors[0][index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        y = self.tensors[1][index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensors[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "define_seed(12)\n",
    "\n",
    "x_train = torch.Tensor(all_data['train']['x'])\n",
    "x_valid = torch.Tensor(all_data['valid']['x'])\n",
    "\n",
    "y_train = torch.LongTensor(all_data['train']['y'])\n",
    "y_valid = torch.LongTensor(all_data['valid']['y'])\n",
    "\n",
    "classes_count = np.array([len(np.where(y_train == t)[0]) for t in np.unique(y_train)])\n",
    "weight = 1. / classes_count\n",
    "samples_weight = torch.from_numpy(np.array([weight[t] for t in y_train])).double()\n",
    "\n",
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "\n",
    "train_dataset = CustomTensorDataset(tensors=(x_train, y_train), transform=None)\n",
    "valid_dataset = CustomTensorDataset(tensors=(x_valid, y_valid), transform=None)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                               num_workers=6, sampler=sampler)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, \n",
    "                                               shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transfer_Cnn14(nn.Module):\n",
    "    def __init__(self, pretrained_path, classes_num, pretrain, freeze_base):\n",
    "        \"\"\"Classifier for a new task using pretrained Cnn14 as a sub module.\n",
    "        \"\"\"\n",
    "        super(Transfer_Cnn14, self).__init__()\n",
    "\n",
    "        self.load_base(pretrain, pretrained_path)\n",
    "        \n",
    "        self.base.spectrogram_extractor = nn.Identity()\n",
    "        self.base.logmel_extractor = nn.Identity()\n",
    "        self.base.spec_augmenter = nn.Identity()\n",
    "\n",
    "        # Transfer to another task layer\n",
    "        self.classifier = nn.Linear(2048, classes_num, bias=True)\n",
    "\n",
    "        if freeze_base:\n",
    "            for param in self.base.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "    def load_base(self, pretrain, pretrained_path):\n",
    "        self.base = Cnn14(sample_rate=16000, window_size=1024, hop_size=320, mel_bins=64, \n",
    "                          fmin=50, fmax=14000, classes_num=527)\n",
    "        \n",
    "        if pretrain:\n",
    "            logging.info('Load pretrained model from {}'.format(pretrained_path))\n",
    "            checkpoint = torch.load(pretrained_path)\n",
    "            self.base.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.classifier)\n",
    "\n",
    "    def forward(self, x, mixup_lambda=None):\n",
    "        \"\"\"Input: (batch_size, 1, time_steps, mel_bins)\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(1).transpose(2, 3)\n",
    "        output_dict = self.base(x, mixup_lambda)\n",
    "        embedding = output_dict['embedding']\n",
    "\n",
    "        clipwise_output =  self.classifier(embedding)\n",
    "        output_dict['clipwise_output'] = clipwise_output\n",
    " \n",
    "        return output_dict['clipwise_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score\n",
    "\n",
    "def custom_score(targets, predicts, average='macro'):\n",
    "    return 0.67 * f1_score(targets, predicts, average='macro') + 0.33 * accuracy_score(targets, predicts) \n",
    "\n",
    "define_seed(12)\n",
    "pretrained_path = '../models/pretrained/Cnn14_mAP=0.431.pth'\n",
    "model = Transfer_Cnn14(pretrained_path=pretrained_path, classes_num=len(class_names), \n",
    "                       pretrain=True, freeze_base=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999), \n",
    "                             eps=1e-08, weight_decay=0., amsgrad=True)\n",
    "\n",
    "model, max_epoch, max_performance = train_model(model, loss, optimizer, None, num_epochs=200, \n",
    "                                                device=device, train_dataloader=train_dataloader, \n",
    "                                                valid_dataloader=valid_dataloader,\n",
    "                                                class_names=class_names,\n",
    "                                                log_root=log_root,\n",
    "                                                tb_log_root=tb_log_root,\n",
    "                                                features_name=features_type,\n",
    "                                                experiment_name='fg2020-Weighted-PANN-CNN14-200',\n",
    "                                                metrics=[custom_score, f1_score, accuracy_score],\n",
    "                                                log_iter=[])\n",
    "    \n",
    "print('Epoch: {0}\\n'.format(max_epoch))\n",
    "print(max_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, f1_score, accuracy_score\n",
    "\n",
    "def custom_score(targets, predicts, average='macro'):\n",
    "    return 0.67 * f1_score(targets, predicts, average='macro') + 0.33 * accuracy_score(targets, predicts) \n",
    "\n",
    "def predict_proba(x, y, model, model_name, model_epoch, log_root, batch_size):\n",
    "#     print('Initialize data')\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    dataset = CustomTensorDataset(tensors=(x, y), transform=None)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=6)\n",
    "\n",
    "#     print('Initialize model')\n",
    "    dictionary_path = get_model_by_epoch(os.path.join(log_root, '{0}'.format(model_name)), model_epoch)\n",
    "#     print(dictionary_path)\n",
    "    checkpoint = torch.load(dictionary_path)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "#     print('Testing')\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        predicts = None\n",
    "        with torch.set_grad_enabled(False):\n",
    "            preds = model(inputs)\n",
    "        \n",
    "        predicts = torch.nn.functional.softmax(preds, dim=1).data.cpu().numpy()\n",
    "        all_labels.append(labels.data.cpu().numpy())\n",
    "        all_predictions.append(predicts)\n",
    "        \n",
    "    return np.concatenate(all_predictions), np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = '../models/pretrained/Cnn14_mAP=0.431.pth'\n",
    "model = Transfer_Cnn14(pretrained_path=pretrained_path, \n",
    "                       classes_num=len(class_names), \n",
    "                       pretrain=True, \n",
    "                       freeze_base=False)\n",
    "\n",
    "model_name = 'mel_64x32_fg2020-Weighted-PANN-CNN14-200'\n",
    "\n",
    "x_train = torch.Tensor(all_data['train']['x'])\n",
    "x_valid = torch.Tensor(all_data['valid']['x'])\n",
    "\n",
    "y_train = torch.LongTensor(all_data['train']['y'])\n",
    "y_valid = torch.LongTensor(all_data['valid']['y'])\n",
    "\n",
    "probas, labels = predict_proba(x_train, y_train, model, model_name, 199, log_root, batch_size)\n",
    "preds = probas.argmax(axis=1)\n",
    "print('Metrics: F1: {0}, Acc: {1}, Custom: {2}'.format(f1_score(labels, preds, average='macro'),\n",
    "                                                       accuracy_score(labels, preds),\n",
    "                                                       custom_score(labels, preds, 'macro')))\n",
    "\n",
    "probas, labels = predict_proba(x_valid, y_valid, model, model_name, 199, log_root, batch_size)\n",
    "preds = probas.argmax(axis=1)\n",
    "print('Metrics: F1: {0}, Acc: {1}, Custom: {2}'.format(f1_score(labels, preds, average='macro'),\n",
    "                                                       accuracy_score(labels, preds),\n",
    "                                                       custom_score(labels, preds, 'macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253/253 [04:34<00:00,  1.08s/it]\n",
      "100%|██████████| 70/70 [01:17<00:00,  1.11s/it]\n",
      "100%|██████████| 223/223 [03:51<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "pretrained_path = '../models/pretrained/Cnn14_mAP=0.431.pth'\n",
    "model = Transfer_Cnn14(pretrained_path=pretrained_path, \n",
    "                       classes_num=len(class_names), \n",
    "                       pretrain=True, \n",
    "                       freeze_base=False)\n",
    "\n",
    "model_name = 'mel_64x32_fg2020-Weighted-PANN-CNN14-200'\n",
    "\n",
    "for ds in ['train', 'valid', 'test']:\n",
    "    for f in tqdm(files_data[ds]):\n",
    "        x_train = torch.Tensor(files_data[ds][f]['x'])\n",
    "        y_train = torch.LongTensor(files_data[ds][f]['y'])\n",
    "        \n",
    "        probas, labels = predict_proba(x_train, y_train, model, model_name, 199, log_root, batch_size)\n",
    "        \n",
    "        res = np.concatenate((probas, np.expand_dims(labels, axis=1)), axis=1)\n",
    "        \n",
    "        os.makedirs(os.path.join(model_name, ds), exist_ok=True)\n",
    "        \n",
    "        fn = os.path.splitext(os.path.basename(f))[0]\n",
    "        np.savetxt(os.path.join(model_name, ds, \"{0}.csv\".format(fn)), res, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlenv)",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
